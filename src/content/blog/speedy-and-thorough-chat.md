---
draft: false
title: "Rebranding to SpeedyDesk?"
snippet: "Find out why WiselyDesk is the fastest and most helpful AI chat available."
image: {
    src: "/apples-to-oranges.png",
    alt: "Lightning"
}
publishDate: "2023-04-18 08:39"
category: "Learning"
author: "Jay Chiarella"
tags: [streaming, speed improvements, new features, gpt4]
---

## Intro 

We reduced the time your users have to wait for the first words of the answer by two seconds. We are also using the GPT-4 AI models, when necessary, to generate even more thorough and helpful answers. 

### Jargon explanation:

**Streaming Response:** Get your answer a word at a time instead of all at once.

<hr />

## Speedy answers

We decreased the time it takes your users to start getting their answer by simplifying how we store the word embeddings / numerical representation of your knowledge base content. 

Instead of storing this information in a database somewhere outside our servers, we store this information in JSON files close to our servers. Simple, we know - but it works!

## Thorough answers

By switching to mostly using the GPT-4 AI model, we're able to provide answers that are even more thorough and helpful to your users. We think that using GPT-3.5 AI answers are usually within an average range - while the GPT-4 AI answers are usually above average in quality. 

Below is a comparasion of the same question in the GPT-3.5 and GPT-4 answers: 

<div class="text-center mt-16">
<sup >GPT-3.5</sup>
</div>
<img src="/gpt-3.5-response.png" alt="GPT-3.5 response" class="mb-1 rounded mt-0">

<div class="text-center mt-4">
<sup >GPT-4</sup>
</div>
<img src="/gpt-4-response.png" alt="GPT-4 response" class="mb-1 rounded mt-0">

We think the GPT-4 answer is more helpful because it: 

1. Provides more information while being relevant
2. Separates content with paragraphs
3. Guesses the intent and advises the user to sign up .. underrated growth hacker?

## Streaming responses

Since GPT-4 answers are more thorough, it takes longer - around 20 to 30 seconds in our testing - for the AI model to generate the entire answer. 

However, your users can start getting the answer almost instantly if the chat streams the response from OpenAI. This way your users won't wait the 20 to 30 seconds to start getting an answer to their question.

<div class="text-center mt-16">
<sup >Streaming vs non-streaming response.</sup>
</div>
<img src="/streaming-response.png" alt="Streaming vs non streaming response" class="mb-1 rounded mt-0">

### Comparing WiselyDesk and our leading CRM systems

*Note: please reach out or call us out if any of this information is misleading. We want to be a trusted source for support professionals, so accuracy is a must.*

Let's compare WiselyDesk's AI chat with the native GPT AI features of leading CRM systems.

#### Intercom

Using the FIN GPT-4 demo, it seems that most questions take between 20-30 seconds to receive the response. The reason is because they don't stream the response from OpenAI, they send the full answer once it's complete.

#### Zendesk

No native GPT-4 AI chatbot features announced. However, since their existing chat does not support streaming, your users would need to wait the 20-30 seconds to receive the response even if this feature is launched in the current state.

#### Freshdesk

Nope

<div class="text-center mt-16">
<sup >Comparing native GPT features of </sup>
</div>
<img src="/feature-comparison.png" alt="GPT powered feature comparison" class="mb-1 rounded mt-0">

<hr />

#### Isn't the GPT-4 more expensive

Yes it is. However, we have and will continue to engineer our system to reduce the costs as much as possible. Some examples are using the less expensive models when the question does not need to use the full power of GPT-4

### Outro

WiselyDesk is the **fastest** and most **helpful** AI chat system available. Point us to your help center and we'll have a demo using your content within a day - <a href="https://www.wiselydesk.com/contact" target="_blank">reach out here!</a>



